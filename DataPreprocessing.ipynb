{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f310bbba",
   "metadata": {},
   "source": [
    "# Student Performance Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e69eef4",
   "metadata": {},
   "source": [
    "The following list contains the data transformations that we intend to apply to the dataset:\n",
    "1. Concatenate math and Portuguese data\n",
    "2. Split data into train and test sets\n",
    "3. Remove columns that do not help our model generalize for all students\n",
    "4. Remove columns with little/no correlation with target variable to reduce noise in the dataset\n",
    "5. Remove columns with high correlation with other columns to reduce multicollinearity in the dataset\n",
    "6. Standardize or normalize all numberic columns so they are on the same scale\n",
    "7. Encode the ordinal categorical variables\n",
    "8. One-hot encode the nominal categorical variables\n",
    "\n",
    "See DataExploration.ipynb for justification of the above transformations.\n",
    "\n",
    "We want to ultimately evaluate our models using cross-validation. However, to improve training time and allow us to experiment faster, we will try out algorithms using a generic train-test-split and then apply cross-validation to the models that perform the best on the split data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d390e2a",
   "metadata": {},
   "source": [
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c0dd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34aa55",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a413e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE = 12\n",
    "TEST_SIZE = 0.1\n",
    "TRAIN_FILE = 'data/processed/train.csv'\n",
    "TEST_FILE = 'data/processed/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d79e32",
   "metadata": {},
   "source": [
    "### Read data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1160591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_data = pd.read_csv(filepath_or_buffer = 'data/student-mat.csv', sep=';', header=0)\n",
    "port_data = pd.read_csv(filepath_or_buffer = 'data/student-por.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "537ef6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([math_data, port_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f5cfd",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bc9e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'G3']\n",
    "y = df['G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a5b393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RAND_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b58bf",
   "metadata": {},
   "source": [
    "### Define preprocessing transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ea493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numerical attributes to keep - note that we are treating the ordinal variables (such as traveltime and studytime) as numeric because they have already been encoded\n",
    "numeric_cols_to_keep = ['age', 'Medu', 'traveltime', 'studytime', 'failures', 'goout', 'Dalc', 'absences']\n",
    "# define nominal attributes to keep\n",
    "nominal_cols_to_keep = ['address', 'Fjob', 'guardian', 'higher', 'internet', 'romantic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "834117b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "         transformers = [(\"numeric\", MinMaxScaler(), numeric_cols_to_keep),\n",
    "                         (\"nominal\", OneHotEncoder(drop='if_binary', handle_unknown='error'), nominal_cols_to_keep)],\n",
    "         remainder = 'drop',\n",
    "         n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb6dfc",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8776a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = ct.fit_transform(X_train)\n",
    "X_test_processed = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66f7460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names from transformers\n",
    "nominal_col_names = ct.transformers_[1][1].get_feature_names(input_features=nominal_cols_to_keep)\n",
    "transformed_col_names = np.concatenate([numeric_cols_to_keep, nominal_col_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd81ca2",
   "metadata": {},
   "source": [
    "Convert numpy arrays back into Pandas dataframes and add back target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "717d7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(X_train_processed, columns = transformed_col_names)\n",
    "train_df['G3'] = np.array(y_train)\n",
    "test_df = pd.DataFrame(X_test_processed, columns = transformed_col_names)\n",
    "test_df['G3'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ac855",
   "metadata": {},
   "source": [
    "### Write processed data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f7b338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1967c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(path_or_buf = TRAIN_FILE, header=True)\n",
    "test_df.to_csv(path_or_buf = TEST_FILE, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
