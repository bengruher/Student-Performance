{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9971c108",
   "metadata": {},
   "source": [
    "# Student Performance Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beabd595",
   "metadata": {},
   "source": [
    "Approach:\n",
    "1. Use train/test split data to try a number of different algorithms/techniques.\n",
    "2. Choose the most promising algorithms and optimize hyperparameters.\n",
    "3. Validate results using cross-validation on the entire dataset.\n",
    "\n",
    "Algorithms to try:\n",
    "- Linear regression\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Decision tree\n",
    "- Support Vector Machine (SVM)\n",
    "- Ensemble - RandomForest, XGBoost, stacking, etc\n",
    "- Multi-layer perceptron (MLP)\n",
    "\n",
    "Success criteria: \n",
    "\n",
    "Without knowledge of the first two term grades, the best model in the original paper had an root mean-squared error (RMSE) of 2.67 on the Portuguese dataset and 3.90 on the mathematics dataset. Since we are combining the two datasets, it may be difficult to compare our results with the results of the original paper. However, we are hoping to create a model that can produce results with a **RMSE of <2**. These results would demonstrate that the model has significant skill and is able to produce reasonably accurate predictions for a student's year-long grades. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64df14",
   "metadata": {},
   "source": [
    "### Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b74937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2136b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086879a",
   "metadata": {},
   "source": [
    "### Creating directory for model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2567f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_prefix = 'artifacts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8e5f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $artifact_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2bd47",
   "metadata": {},
   "source": [
    "### Define contants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1dd03d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE = 12\n",
    "TRAIN_FILE = 'data/processed/train.csv'\n",
    "TEST_FILE = 'data/processed/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9db69",
   "metadata": {},
   "source": [
    "### Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8ef40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_FILE, header=0)\n",
    "test_df = pd.read_csv(TEST_FILE, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d9a98",
   "metadata": {},
   "source": [
    "Seperate attributes and target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07a96e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.loc[:, train_df.columns != 'G3']\n",
    "y_train = train_df['G3']\n",
    "X_test = test_df.loc[:, test_df.columns != 'G3']\n",
    "y_test = test_df['G3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23793f",
   "metadata": {},
   "source": [
    "### Define model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc0b6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the root mean squared error (RMSE) and R-squared value given a set of predicted and actual values\n",
    "def evaluate(actual, predictions):\n",
    "    return mean_squared_error(y_true = actual, y_pred = predictions, squared = False), r2_score(actual, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb92ff1",
   "metadata": {},
   "source": [
    "### Create baseline naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1fb16",
   "metadata": {},
   "source": [
    "We first want to create a baseline model to compare resuls as we test new algorithms. For our baseline regressor, we will be creating a naive model that always returns the average grade for students in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e6cad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveRegressor(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def fit(self, X_train, y_train):\n",
    "        # calculate average grade in training set\n",
    "        self.value = np.average(y_train)\n",
    "        return\n",
    "    def predict(self, values):\n",
    "        predictions = list()\n",
    "        for row in np.array(values):\n",
    "            predictions.append(self.value)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe27393",
   "metadata": {},
   "source": [
    "Now we want to evaluate our baseline model against the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9ea35a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train baseline model\n",
    "baseline = NaiveRegressor()\n",
    "baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e01668fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "baseline_predictions = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ef03717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE:  3.7025421957351212\n",
      "Baseline R2:  -0.01542370731080589\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "baseline_score = evaluate(y_test, baseline_predictions)\n",
    "print('Baseline RMSE: ', baseline_score[0])\n",
    "print('Baseline R2: ', baseline_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd17c5",
   "metadata": {},
   "source": [
    "This baseline RMSE score is roughly consistent with the results found in the original paper. Although the original study separated math and Portuguese classes, the RMSE's of their Naive regression model were 4.6 and 3.2 respectively. We will log this model using MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ff6ca12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_prefix = 'baseline/'\n",
    "!mkdir -p {artifact_prefix + baseline_prefix}\n",
    "baseline_model_path = artifact_prefix + baseline_prefix + 'model.pkl'\n",
    "baseline_artifacts = {\"baseline_model_path\": baseline_model_path}\n",
    "with open(baseline_model_path, 'wb') as f:\n",
    "    pickle.dump(baseline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f7c2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "#     mlflow.log_param(\"alpha\", alpha)\n",
    "#     mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "    mlflow.log_metric(\"rmse\", baseline_score[0])\n",
    "    mlflow.log_metric(\"r2\", baseline_score[1])\n",
    "\n",
    "#     mlflow.log_artifact(\"encoder.pickle\")\n",
    "    \n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path='baseline',\n",
    "        python_model=NaiveRegressor(),\n",
    "#         code_path=[\"./artifacts\"],\n",
    "        artifacts=baseline_artifacts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772963a",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ac321ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model\n",
      "  RMSE: 3.3953687970141377\n",
      "  R2: 0.14607216161348102\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate Metrics\n",
    "    predictions = lr.predict(X_test)\n",
    "    rmse, r2 = evaluate(y_test, predictions)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(\"Linear Regression model\")\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log metrics and model to MLflow\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"LinRegModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030fa24",
   "metadata": {},
   "source": [
    "The scikit-learn Linear Regression model with default hyperparameters did improve over the baseline model. The RMSE improved to ~3.4 from 3.7 and the R-squared score improved from ~0 to 0.14. While the improvement in R-squared score is encouraging, it's possible that the relationship between the features and the target variable is not linear. We will explore some non-linear options next. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f4592",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5ba5d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN model\n",
      "  RMSE: 3.9511300372714353\n",
      "  R2: -0.1563516164574994\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    knn = KNeighborsRegressor()\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate Metrics\n",
    "    predictions = knn.predict(X_test)\n",
    "    rmse, r2 = evaluate(y_test, predictions)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(\"KNN model\")\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log metrics, and model to MLflow\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(knn, \"KNNModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361b8cc",
   "metadata": {},
   "source": [
    "Surprisingly, the KNN scikit-learn with default hyperparameters did worse than our baseline model. Both the RMSE and the R-squared score were worse than that of the baseline. We previously thought that students who were close together in the feature space would be similar in many ways, including school performance. However, this is clearly not the case for this set of students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bd9633",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "652ac927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model\n",
      "  RMSE: 4.8245404419685896\n",
      "  R2: -0.7240869635322891\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    dt = DecisionTreeRegressor()\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate Metrics\n",
    "    predictions = dt.predict(X_test)\n",
    "    rmse, r2 = evaluate(y_test, predictions)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(\"Decision Tree model\")\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log metrics, and model to MLflow\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(dt, \"DecisionTreeModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867783ef",
   "metadata": {},
   "source": [
    "The scikit-learn Decision Tree regression algorithm with default hyperparameters is much worse than our baseline algorithm. We may try to tune some of the hyperparameters to see if it will do any better but for now, we will move on to other algorithm types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39cfd55",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e6dc5fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model\n",
      "  RMSE: 3.739125728684253\n",
      "  R2: -0.03558893804497831\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    svm = SVR()\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate Metrics\n",
    "    predictions = svm.predict(X_test)\n",
    "    rmse, r2 = evaluate(y_test, predictions)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(\"SVM model\")\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "\n",
    "    # Log metrics, and model to MLflow\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(svm, \"SVMModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8f819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
